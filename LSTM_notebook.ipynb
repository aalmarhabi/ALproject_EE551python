{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: Load the dataset\n",
    "### we will use MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/01/03fd7e503c16b3dc262483e5555ad40974ab5da8b9879e164b56c1f4ef6f/torchvision-0.2.2.post3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: torch in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.0.1.post2)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.15.4)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /anaconda3/lib/python3.7/site-packages (from torchvision) (5.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.2.2.post3\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as mnistdt\n",
    "# from Model.Models import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the trainning and test data \n",
    "\n",
    "traindt = mnistdt.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "testdt = mnistdt.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning dataset size torch.Size([60000, 28, 28])\n",
      "Trainning dataset labels torch.Size([60000])\n",
      "Testing dataset size torch.Size([10000, 28, 28])\n",
      "Testning dataset labels torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print('Trainning dataset size', traindt.train_data.size())\n",
    "print('Trainning dataset labels', traindt.train_labels.size())\n",
    "print('Testing dataset size', testdt.test_data.size())\n",
    "print('Testning dataset labels', testdt.test_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we use pytorch dataloader to iterate, set number of batch and apply transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(traindt) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=traindt, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testdt, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a LSTM class \n",
    "#### or import if using python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    # Initialize class\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        # 28 time steps\n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and setup optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.2540340423583984. Accuracy: 22\n",
      "Iteration: 1000. Loss: 0.9567198753356934. Accuracy: 69\n",
      "Iteration: 1500. Loss: 0.4429047703742981. Accuracy: 87\n",
      "Iteration: 2000. Loss: 0.3745232820510864. Accuracy: 90\n",
      "Iteration: 2500. Loss: 0.24429967999458313. Accuracy: 95\n",
      "Iteration: 3000. Loss: 0.18545639514923096. Accuracy: 95\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 28  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # apply backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #  correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
